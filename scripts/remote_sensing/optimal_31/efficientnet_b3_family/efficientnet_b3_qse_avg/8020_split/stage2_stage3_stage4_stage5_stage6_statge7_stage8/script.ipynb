{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from torchvision.models import efficientnet_b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadrantSqueezeExcitation(nn.Module):\n",
    "  def __init__(self, in_channels, reduction_dim):\n",
    "    super(QuadrantSqueezeExcitation, self).__init__()\n",
    "    self.avgpool = nn.AdaptiveAvgPool2d((2,2))\n",
    "    # self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=reduction_dim, kernel_size=(1,1), stride=(1,1))\n",
    "    # self.conv2 = nn.Conv2d(in_channels=reduction_dim, out_channels=in_channels, kernel_size=(1,1), stride=(1,1))\n",
    "    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=reduction_dim, kernel_size=(1,1), stride=(1,1))\n",
    "    self.conv2 = nn.Conv2d(in_channels=reduction_dim, out_channels=in_channels, kernel_size=(1,1), stride=(1,1))\n",
    "    self.activation = nn.SiLU()\n",
    "    self.scale_activation = nn.Sigmoid()\n",
    "  def forward(self, x):\n",
    "    residual = x.clone()\n",
    "    b,c,h,w = x.size()\n",
    "    x = self.avgpool(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.activation(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.scale_activation(x)\n",
    "    # Apply scaling to the quadrants without additional cloning\n",
    "    residual[:, :, 0:int(h/2), 0:int(w/2)] *= x[:, :, 0:1, 0:1]  # Top-left\n",
    "    residual[:, :, 0:int(h/2), int(w/2):w] *= x[:, :, 0:1, 1:2]  # Top-right\n",
    "    residual[:, :, int(h/2):h, 0:int(w/2)] *= x[:, :, 1:2, 0:1]  # Bottom-left\n",
    "    residual[:, :, int(h/2):h, int(w/2):w] *= x[:, :, 1:2, 1:2]  # Bottom-right\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetB3QSE(nn.Module):\n",
    "  def __init__(self, num_classes, stages):\n",
    "    super(EfficientNetB3QSE, self).__init__()\n",
    "    self.model = efficientnet_b3(weights=\"IMAGENET1K_V1\", progress=True)\n",
    "    self.model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3, inplace=True), \n",
    "        nn.Linear(in_features=1536, out_features=num_classes, bias=True)\n",
    "    )\n",
    "    for param in self.model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in self.model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    # qse in stage 2\n",
    "    if 2 in stages:\n",
    "        self.model.features[1][0].block[1] = QuadrantSqueezeExcitation(40,10)\n",
    "        self.model.features[1][1].block[1] = QuadrantSqueezeExcitation(24,6)\n",
    "    # qse in stage 3\n",
    "    if 3 in stages:\n",
    "        self.model.features[2][0].block[2] = QuadrantSqueezeExcitation(144,6)\n",
    "        for i in range(1,3):\n",
    "          self.model.features[2][1].block[2] = QuadrantSqueezeExcitation(192,8)\n",
    "    # qse in stage 4\n",
    "    if 4 in stages:\n",
    "      self.model.features[3][0].block[2] = QuadrantSqueezeExcitation(192,8)\n",
    "      for i in range(1,3):  \n",
    "        self.model.features[3][i].block[2] = QuadrantSqueezeExcitation(288,12)\n",
    "    # qse in stage 5\n",
    "    if 5 in stages:\n",
    "      self.model.features[4][0].block[2] = QuadrantSqueezeExcitation(288,12)\n",
    "      for i in range(1,5):\n",
    "        self.model.features[4][i].block[2] = QuadrantSqueezeExcitation(576,24)\n",
    "    # qse in stage 6\n",
    "    if 6 in stages:\n",
    "      self.model.features[5][0].block[2] = QuadrantSqueezeExcitation(576,24)\n",
    "      for i in range(1,5):\n",
    "        self.model.features[5][i].block[2] = QuadrantSqueezeExcitation(816,34)\n",
    "    # qse in stage 7\n",
    "    if 7 in stages:\n",
    "      self.model.features[6][0].block[2] = QuadrantSqueezeExcitation(816,34)\n",
    "      for i in range(1,6):\n",
    "        self.model.features[6][i].block[2] = QuadrantSqueezeExcitation(1392,58)\n",
    "    # qse in stage 8\n",
    "    if 8 in stages:\n",
    "      self.model.features[7][0].block[2] = QuadrantSqueezeExcitation(1392,58)\n",
    "      self.model.features[7][1].block[2] = QuadrantSqueezeExcitation(2304,96)\n",
    "  def forward(self, x):\n",
    "    return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {\n",
    "    0: \"airplane\",\n",
    "    1: \"airport\",\n",
    "    2: \"baseball diamond\",\n",
    "    3: \"basketball court\",\n",
    "    4: \"beach\",\n",
    "    5: \"bridge\",\n",
    "    6: \"chaparral\",\n",
    "    7: \"church\",\n",
    "    8: \"circular farmland\",\n",
    "    9: \"commercial area\",\n",
    "    10: \"dense residential\", \n",
    "    11: \"desert\",\n",
    "    12: \"forest\", \n",
    "    13: \"freeway\",\n",
    "    14: \"golf course\",\n",
    "    15: \"ground track field\", \n",
    "    16: \"harbor\",\n",
    "    17: \"industrial area\", \n",
    "    18: \"intersection\", \n",
    "    19: \"island\", \n",
    "    20: \"lake\",\n",
    "    21: \"meadow\", \n",
    "    22: \"medium residential\", \n",
    "    23: \"mobile home park\",\n",
    "    24: \"mountain\",\n",
    "    25: \"overpass\",\n",
    "    26: \"parking lot\", \n",
    "    27: \"railway\",\n",
    "    28: \"rectangular farmland\",\n",
    "    29: \"roundabout\",\n",
    "    30: \"runway\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/jonathan-roberts1/Optimal-31/data/train-00000-of-00001-6f3929acf058ef6f.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_image(byte_data):\n",
    "    image = Image.open(io.BytesIO(byte_data[\"bytes\"]))  # Convert bytes to PIL image\n",
    "    return image\n",
    "\n",
    "df[\"image\"] = df[\"image\"].apply(bytes_to_image)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df.sample(n=16)\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 5))\n",
    "axes = axes.ravel()\n",
    "for i, (index, row) in enumerate(sampled_df.iterrows()):\n",
    "    img = row['image']\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(label[row['label']], fontsize=10)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal-31 is 256 by 256\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(degrees=(-180, 180)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs, scheduler, best_model_params_path, best_accuracy):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    since = time.time()\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch == 10:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "        # print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        # print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                for param in model.parameters():\n",
    "                    param.grad = None\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            if phase == \"train\":\n",
    "                train_accuracies.append(epoch_acc)\n",
    "            else:\n",
    "                val_accuracies.append(epoch_acc)\n",
    "\n",
    "            # print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_accuracy:\n",
    "                best_accuracy = epoch_acc\n",
    "                if best_model_params_path != None:\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "        #             print(f\"Current Best Accuracy:{best_accuracy}\")\n",
    "\n",
    "        # print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {max(tensor.cpu().item() for tensor in val_accuracies):4f}')\n",
    "\n",
    "    return train_accuracies, val_accuracies, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.dataframe.iloc[idx]['image']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters follow the efficientnetb3attn paper\n",
    "def main(stages, test_size, results_path):\n",
    "    X = df[\"image\"]\n",
    "    y = df[\"label\"]\n",
    "    accuracies_dict = {}\n",
    "    accuracies_dict[\"train\"] = []\n",
    "    accuracies_dict[\"val\"] = []\n",
    "    best_accuracy = 0.0\n",
    "    for i in range(20):\n",
    "        print(\"-\"*10)\n",
    "        print(f\"Iteration: {i+1}\")\n",
    "        print(\"-\"*10)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, stratify=y)\n",
    "        train_dataset = ImageDataset(dataframe=pd.concat([X_train, y_train], axis=1), transform=data_transforms[\"train\"])\n",
    "        val_dataset = ImageDataset(dataframe=pd.concat([X_val, y_val], axis=1), transform=data_transforms[\"val\"])\n",
    "        dataloaders = {}\n",
    "        dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model = EfficientNetB3QSE(num_classes=31, stages=stages)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[75], gamma=0.1)\n",
    "        NUM_EPOCHS = 40\n",
    "        best_model_params_path = \"./best_model_parameters.pth\"\n",
    "        train_accuracies, val_accuracies, best_accuracy = train_model(model, dataloaders, criterion, optimizer, NUM_EPOCHS, scheduler, best_model_params_path, best_accuracy)\n",
    "        accuracies_dict[\"train\"].append(train_accuracies)\n",
    "        accuracies_dict[\"val\"].append(val_accuracies)\n",
    "    with open(results_path, 'wb') as file:\n",
    "        pickle.dump(accuracies_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(data):\n",
    "    num_rounds = 5\n",
    "    num_epochs = 50\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(num_rounds, 1, figsize=(10, 15))\n",
    "    \n",
    "    for i in range(num_rounds):\n",
    "        # Extract training and validation data for the current round\n",
    "        train_data = data['train'][i]\n",
    "        val_data = data['val'][i]\n",
    "\n",
    "        # Move tensors to CPU and convert to numpy\n",
    "        train_data_cpu = [tensor.cpu().item() for tensor in train_data]\n",
    "        val_data_cpu = [tensor.cpu().item() for tensor in val_data]\n",
    "\n",
    "        # Plotting\n",
    "        axes[i].plot(train_data_cpu, label='Train', color='blue', marker='o')\n",
    "        axes[i].plot(val_data_cpu, label='Validation', color='orange', marker='x')\n",
    "        \n",
    "        # Adding titles and labels\n",
    "        axes[i].set_title(f'Round {i + 1}')\n",
    "        axes[i].set_xlabel('Epochs')\n",
    "        axes[i].set_ylabel('Accuracy')\n",
    "        axes[i].set_xticks(range(num_epochs))\n",
    "        axes[i].set_xticklabels(range(1, num_epochs + 1))\n",
    "        axes[i].legend()\n",
    "        axes[i].grid()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal function\n",
    "def calculate_max_val_accuracy(data):\n",
    "    max_val_accuracies = []\n",
    "    for val in data['val']:\n",
    "        max_accuracy = max(tensor.cpu().item() for tensor in val)  # Get max accuracy for this iteration\n",
    "        max_val_accuracies.append(max_accuracy)\n",
    "\n",
    "    return max_val_accuracies\n",
    "\n",
    "def calculate_margin_of_error(data, alpha):\n",
    "    max_val_accuracies = calculate_max_val_accuracy(data)\n",
    "    mean_val_accuracy = np.mean(max_val_accuracies)\n",
    "    std_dev = np.std(max_val_accuracies, ddof=1)  # Sample standard deviation\n",
    "    n = len(max_val_accuracies)  # Number of iterations\n",
    "\n",
    "    # T-score for 95% confidence level\n",
    "    t_score = stats.t.ppf(1-alpha/2, df=n-1)  # Two-tailed test, df = n - 1\n",
    "\n",
    "    # Calculate margin of error\n",
    "    margin_of_error = t_score * (std_dev / np.sqrt(n))\n",
    "\n",
    "    return mean_val_accuracy, margin_of_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"./train_val_accuracy_log.pkt\"\n",
    "test_size = 0.2\n",
    "stages = [2,3,4,5,6,7,8]\n",
    "main(stages, test_size, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_path, 'rb') as file: \n",
    "    data = pickle.load(file)\n",
    "#visualize_training_results(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val, margin_of_error = calculate_margin_of_error(data, 0.05)\n",
    "print(f\"Mean Highest Validation Accuracy: {mean_val}\")\n",
    "print(f\"Margin of Error: {margin_of_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-test] *",
   "language": "python",
   "name": "conda-env-.conda-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
